## OUT-OF-SAMPLE Prediction
######################################
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
tr = sample(1:506,400)
train = train[tr,]
test = test[-tr,]
out_MSE = NULL
for(i in 2:350){
near = kknn(medv~lstat,train,test,k=i,kernel = "rectangular")
aux = mean((test[,2]-near$fitted)^2)
out_MSE = c(out_MSE,aux)
}
best = which.min(out_MSE)
plot(log(1/(2:350)),sqrt(out_MSE),xlab="Complexity (log(1/k))",ylab="out-of-sample RMSE",col=4,lwd=2,type="l",cex.lab=1.2)
text(log(1/best),sqrt(out_MSE[best])+0.3,paste("k=",best),col=2,cex=1.2)
text(log(1/2),sqrt(out_MSE[2]),paste("k=",2),col=2,cex=1.2)
text(log(1/354)+0.4,sqrt(out_MSE[345]),paste("k=",345),col=2,cex=1.2)
near = kknn(medv~lstat,train,test,k=42,kernel = "rectangular")
ind = order(test[,1])
plot(lstat,medv,main=paste("k=",42),pch=19,cex=0.8,col="darkgray")
lines(test[ind,1],near$fitted[ind],col=2,lwd=2)
#########################################
# leave-one-out cross validation (LOOCV)#
#########################################
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
out_MSE = matrix(0,n,100)
for(j in 1:n){
train_i = train[-j,]
test_i = test[j,]
for(i in 1:100){
near = kknn(medv~lstat,train_i,test_i,k=i,kernel = "rectangular")
aux = mean((test_i[,2]-near$fitted)^2)
out_MSE[j,i] = aux
}
cat(j,'\n')
}
ls()
lstat()
lstat
names(Boston)
library(MASS) ## a library of example datasets
library(class) ## a library with lots of classification tools
library(kknn) ## knn library
attach(Boston)
n = dim(Boston)[1]
plot(lstat,medv)
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
train
test
ind = order(tetrainst[,1])
ind = order(test[,1])
ind
test =test[ind,]
test
ls()
ls()
library(MASS) ## a library of example datasets
library(class) ## a library with lots of classification tools
library(kknn) ## knn library
attach(Boston)
n = dim(Boston)[1]
plot(lstat,medv)
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
ind = order(test[,1])
test =test[ind,]
MSE = NULL
ls()
kk = c(2,10,50,100,150,200,250,300,400,505)
? kknn
for(i in kk){
near = kknn(medv~lstat,train,test,k=i,kernel = "rectangular")
aux = mean((test[,2]-near$fitted)^2)
MSE = c(MSE,aux)
plot(lstat,medv,main=paste("k=",i),pch=19,cex=0.8,col="darkgray")
lines(test[,1],near$fitted,col=2,lwd=2)
cat ("Press [enter] to continue")
line <- readline()
}
mse
MSE
plot(log(1/kk),sqrt(MSE),type="b",xlab="Complexity (log(1/k))",col="blue",ylab="RMSE",lwd=2,cex.lab=1.2)
text(log(1/kk[1]),sqrt(MSE[1])+0.3,paste("k=",kk[1]),col=2,cex=1.2)
text(log(1/kk[10])+0.4,sqrt(MSE[10]),paste("k=",kk[10]),col=2,cex=1.2)
text(log(1/kk[5])+0.4,sqrt(MSE[5]),paste("k=",kk[5]),col=2,cex=1.2)
near = kknn(medv~lstat,train,test,k=20,kernel = "rectangular")
near
for(i in seq(1,505,by=100)){
ii = near$C[i,1:20]
plot(lstat,medv,main=paste("k=",20),pch=19,cex=0.8,col="darkgray")
lines(test[,1],near$fitted,col=2,lwd=2)
abline(v=test[i,1],col=2,lty=2)
points(lstat[ii],medv[ii],pch=19,col="blue")
cat ("Press [enter] to continue")
line <- readline()
}
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
tr = sample(1:506,400)
train = train[tr,]
test = test[-tr,]
out_MSE = NULL
for(i in 2:350){
near = kknn(medv~lstat,train,test,k=i,kernel = "rectangular")
aux = mean((test[,2]-near$fitted)^2)
out_MSE = c(out_MSE,aux)
}
best = which.min(out_MSE)
bes
best
plot(log(1/(2:350)),sqrt(out_MSE),xlab="Complexity (log(1/k))",ylab="out-of-sample RMSE",col=4,lwd=2,type="l",cex.lab=1.2)
text(log(1/best),sqrt(out_MSE[best])+0.3,paste("k=",best),col=2,cex=1.2)
text(log(1/2),sqrt(out_MSE[2]),paste("k=",2),col=2,cex=1.2)
text(log(1/354)+0.4,sqrt(out_MSE[345]),paste("k=",345),col=2,cex=1.2)
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
out_MSE = matrix(0,n,100)
for(j in 1:n){
train_i = train[-j,]
test_i = test[j,]
for(i in 1:100){
near = kknn(medv~lstat,train_i,test_i,k=i,kernel = "rectangular")
aux = mean((test_i[,2]-near$fitted)^2)
out_MSE[j,i] = aux
}
cat(j,'\n')
}
mMSE = apply(out_MSE,2,mean)
plot(log(1/(1:100)),sqrt(mMSE),xlab="Complexity (log(1/k))",ylab="out-of-sample RMSE",col=4,lwd=2,type="l",cex.lab=1.2)
best = which.min(mMSE)
text(log(1/best),sqrt(mMSE[best])+0.1,paste("k=",best),col=2,cex=1.2)
text(log(1/2),sqrt(mMSE[2])+0.3,paste("k=",2),col=2,cex=1.2)
text(log(1/100)+0.4,sqrt(mMSE[100]),paste("k=",100),col=2,cex=1.2)
library(MASS) ## a library of example datasets
library(class) ## a library with lots of classification tools
library(kknn) ## knn library
attach(Boston)
n = dim(Boston)[1]
plot(lstat,medv)
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
ind = order(test[,1])
test =test[ind,]
MSE = NULL
kk = c(2,10,50,100,150,200,250,300,400,505)
for(i in kk){
near = kknn(medv~lstat,train,test,k=i,kernel = "rectangular")
aux = mean((test[,2]-near$fitted)^2)
MSE = c(MSE,aux)
plot(lstat,medv,main=paste("k=",i),pch=19,cex=0.8,col="darkgray")
lines(test[,1],near$fitted,col=2,lwd=2)
cat ("Press [enter] to continue")
line <- readline()
}
ii = near$C[i,1:20]
plot(lstat,medv,main=paste("k=",20),pch=19,cex=0.8,col="darkgray")
lines(test[,1],near$fitted,col=2,lwd=2)
abline(v=test[i,1],col=2,lty=2)
points(lstat[ii],medv[ii],pch=19,col="blue")
cat ("Press [enter] to continue")
line <- readline()
######################################
## OUT-OF-SAMPLE Prediction
######################################
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
tr = sample(1:506,400)
train = train[tr,]
test = test[-tr,]
out_MSE = NULL
for(i in 2:350){
near = kknn(medv~lstat,train,test,k=i,kernel = "rectangular")
aux = mean((test[,2]-near$fitted)^2)
out_MSE = c(out_MSE,aux)
}
best = which.min(out_MSE)
plot(log(1/(2:350)),sqrt(out_MSE),xlab="Complexity (log(1/k))",ylab="out-of-sample RMSE",col=4,lwd=2,type="l",cex.lab=1.2)
text(log(1/best),sqrt(out_MSE[best])+0.3,paste("k=",best),col=2,cex=1.2)
text(log(1/2),sqrt(out_MSE[2]),paste("k=",2),col=2,cex=1.2)
text(log(1/354)+0.4,sqrt(out_MSE[345]),paste("k=",345),col=2,cex=1.2)
near = kknn(medv~lstat,train,test,k=42,kernel = "rectangular")
ind = order(test[,1])
plot(lstat,medv,main=paste("k=",42),pch=19,cex=0.8,col="darkgray")
lines(test[ind,1],near$fitted[ind],col=2,lwd=2)
#########################################
# leave-one-out cross validation (LOOCV)#
#########################################
train = data.frame(lstat,medv)
test = data.frame(lstat,medv)
out_MSE = matrix(0,n,100)
for(j in 1:n){
train_i = train[-j,]
test_i = test[j,]
for(i in 1:100){
near = kknn(medv~lstat,train_i,test_i,k=i,kernel = "rectangular")
aux = mean((test_i[,2]-near$fitted)^2)
out_MSE[j,i] = aux
}
cat(j,'\n')
}
mMSE = apply(out_MSE,2,mean)
plot(log(1/(1:100)),sqrt(mMSE),xlab="Complexity (log(1/k))",ylab="out-of-sample RMSE",col=4,lwd=2,type="l",cex.lab=1.2)
best = which.min(mMSE)
text(log(1/best),sqrt(mMSE[best])+0.1,paste("k=",best),col=2,cex=1.2)
text(log(1/2),sqrt(mMSE[2])+0.3,paste("k=",2),col=2,cex=1.2)
text(log(1/100)+0.4,sqrt(mMSE[100]),paste("k=",100),col=2,cex=1.2)
library(maps)
ca <- read.csv("CAhousing.csv")
logMedVal <- log(ca$medianHouseValue)
n=dim(ca)[1]
ind = sample(1:n,1000)
Y = logMedVal[ind]
CAdata = ca[ind,]
train = data.frame(Y,CAdata$latitude,CAdata$longitude)
test = data.frame(Y,CAdata$latitude,CAdata$longitude)
near = kknn(Y~.,train,test,k=10,kernel = "rectangular")
res = Y - near$fitted
nclr = 10
plotclr = colorRampPalette(c("cyan","magenta"))(nclr)
predcol = heat.colors(9)[9:1] ## see help(heat.colors)
predbreaks = seq(min(Y),max(Y),length=nclr)
residbreaks = seq(min(res),max(res),length=nclr) # borders of resid color bins
residmap <- function(e){
return(plotclr[cut(drop(e), residbreaks)]) ## cut sorts into bins
}
predmap <- function(y){
return(predcol[cut(drop(y),predbreaks)]) ## cut sorts into bins
}
par(mfrow=c(1,2))
## preds
map('state', 'california')
mtext("fitted values (k=10)",cex=2)
points(test[,3:2], col=predmap(near$fitted), pch=19, cex=1)
map('state', 'california')
mtext("Residuals (k=10)",cex=2)
points(test[,3:2], col=residmap(res), pch=19, cex=1)
n = dim(CAdata)[1]
kcv = 10
n0 = round(n/kcv,0)
out_MSE = matrix(0,kcv,100)
used = NULL
set = 1:n
for(j in 1:kcv){
if(n0<length(set)){val = sample(set,n0)}
if(n0>=length(set)){val=set}
train_i = train[-val,]
test_i = test[val,]
for(i in 1:100){
near = kknn(Y~.,train_i,test_i,k=i,kernel = "rectangular")
aux = mean((test_i[,1]-near$fitted)^2)
out_MSE[j,i] = aux
}
used = union(used,val)
set = (1:n)[-used]
cat(j,'\n')
}
mMSE = apply(out_MSE,2,mean)
par(mfrow=c(1,1))
plot(log(1/(1:100)),sqrt(mMSE),type="l",ylab="out-of-sample RMSE",col=4,lwd=2,main="California Housing (knn)",xlab="Complexity")
best = which.min(mMSE)
text(log(1/best),sqrt(mMSE[best])+0.01,paste("k=",best))
text(log(1/100)+0.4,sqrt(mMSE[100]),"k=100")
text(log(1/1),sqrt(mMSE[1])+0.001,"k=1")
rm(list=ls())
#############################################
# Baseball Examples                         #
#############################################
Data = read.table("RunsPerGame.txt",header=T)
attach(Data)
summary(League)
modelAVG = lm(R.G ~ AVG)
modelSLG = lm(R.G ~ SLG)
modelOBP = lm(R.G ~ OBP)
summary(modelAVG)
rm(list=ls())
#############################################
# Baseball Examples                         #
#############################################
Data = read.table("RunsPerGame.txt",header=T)
attach(Data)
summary(League)
modelAVG = lm(R.G ~ AVG)
modelSLG = lm(R.G ~ SLG)
modelOBP = lm(R.G ~ OBP)
summary(modelAVG)
rm(list=ls())
#############################################
# Baseball Examples                         #
#############################################
Data = read.table("RunsPerGame.txt",header=T)
attach(Data)
summary(League)
modelAVG = lm(R.G ~ AVG)
modelSLG = lm(R.G ~ SLG)
modelOBP = lm(R.G ~ OBP)
summary(modelAVG)
rm(list=ls())
#############################################
# Baseball Examples                         #
#############################################
Data = read.table("RunsPerGame.txt",header=T)
attach(Data)
summary(League)
modelAVG = lm(R.G ~ AVG)
modelSLG = lm(R.G ~ SLG)
modelOBP = lm(R.G ~ OBP)
summary(modelAVG)
install.packages("rattle")
library(rattle)
rattle()
crDf[crDf$Category == 'NON-CRIMINAL',]
library(ggplot2)
crDf = read.csv("sfCrime.csv", header=TRUE, fill=TRUE)
# Exploratory Data Analysis
summary(crDf)
head(crDf)
names(crDf)
nrow(crDf)
# WHERE SHOULDN'T YOU PARK YOUR CAR?
uniDescription = crDf[!duplicated(crDf["Descript"]),"Descript"]
# From the uniDescription, we get a sense of the description which tells us where we should not park cars.
# We find the words AUTO and VEHICLE which indicates crimes related to cars. We should target these places not to park cars.
toMatch = c("AUTO", "VEHICLE")
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address")]
df = as.data.frame(table(add))
df$rank = rank(-df$Freq,ties.method="min")
df = df[order(df$rank,decreasing = F),]
# Top 10 addresses where most of the AUTO/VEHICLE related thefts have happened
df[1:10,]
# Bar plot showing the same
q = qplot(x=add, y=Freq, data=df[1:10,], geom="bar", stat="identity")
q + theme(axis.text.x = element_text(angle = 90, hjust = 1))
# WHAT ARE THE SAFEST LOCATIONS IN SF?
crDf[crDf$Category == 'NON-CRIMINAL',]
setwd("F:/TeamLeada")
library(ggplot2)
crDf = read.csv("sfCrime.csv", header=TRUE, fill=TRUE)
# Exploratory Data Analysis
summary(crDf)
head(crDf)
names(crDf)
nrow(crDf)
# WHERE SHOULDN'T YOU PARK YOUR CAR?
uniDescription = crDf[!duplicated(crDf["Descript"]),"Descript"]
# From the uniDescription, we get a sense of the description which tells us where we should not park cars.
# We find the words AUTO and VEHICLE which indicates crimes related to cars. We should target these places not to park cars.
toMatch = c("AUTO", "VEHICLE")
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address")]
df = as.data.frame(table(add))
df$rank = rank(-df$Freq,ties.method="min")
df = df[order(df$rank,decreasing = F),]
# Top 10 addresses where most of the AUTO/VEHICLE related thefts have happened
df[1:10,]
# Bar plot showing the same
q = qplot(x=add, y=Freq, data=df[1:10,], geom="bar", stat="identity")
q + theme(axis.text.x = element_text(angle = 90, hjust = 1))
# WHAT ARE THE SAFEST LOCATIONS IN SF?
crDf[crDf$Category == 'NON-CRIMINAL',]
crDf$Category == 'NON-CRIMINAL'
crDf[crDf$Category == 'NON-CRIMINAL',"Descript"]
crDf[crDf$Category == 'NON-CRIMINAL',"Address"]
safeAdd = crDf[crDf$Category == 'NON-CRIMINAL',"Address"]
safeDf = as.data.frame(table(safeAdd))
safeDf$rank = rank(-safeDf$Freq,ties.method="min")
safeDf = safeDf[order(safeDf$rank,decreasing = F),]
safeDf
safeDf[1:10]
safeDf[1:10,]
unique(crDf$Category)
safeAdd = crDf[,"Address"]
safeDf = as.data.frame(table(safeAdd))
safeDf$rank = rank(-safeDf$Freq,ties.method="min")
safeDf = safeDf[order(safeDf$rank,decreasing = T),]
safeDf[1:10,]
safeDf[1:20,]
summary(safeDf)
dangerousDay = crDf[,c("DayOfWeek","Time")]
dangDf = as.data.frame(table(dangerousDay))
head(dangDf)
dangerousDay = crDf[,c("DayOfWeek")]
dangDf = as.data.frame(table(dangerousDay))
dangDf$rankDay = rank(-dangDf$Freq, ties.method="min")
dangDf = dangDf[order(dangDf$rank, decreasing=F)]
dangDf = dangDf[order(dangDf$rank, decreasing=F),]
dangerousDay = crDf[,c("DayOfWeek")]
dangDf = as.data.frame(table(dangerousDay))
dangDf
crDf[, list(addrs = list(crDf$Address)), by = crDf$Descript]
table(crDf$Descript)
toMatch = c("THEFT")
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address")]
add
grep(paste(toMatch, collapse="|"), crDf[,"Descript"]
)
toMatch = c("AUTO", "VEHICLE")
grep(paste(toMatch, collapse="|"), crDf[,"Descript"])
head(add)
uniDescription = crDf[!duplicated(crDf["Descript"]),"Descript"]
uniDescription
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address", "Descript")]
toMatch = c("THEFT")
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address", "Desscript")]
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address"), c("Address", "Descript")]
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address"), ]
head(add)
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address","Descript") ]
head(add)
table(add)
head(table(add))
head(add)
add
add$Count = 1
head(add)
library(data.table)
dtAdd = data.table(add)
install.packages("data.table")
library(data.table)
dtAdd = data.table(add)
dtAdd[,Freq:=sum(Count), by=list(Address, Descript)]
dtAdd
toMatch = c("THEFT")
add = crDf[grep(paste(toMatch, collapse="|"), crDf[,"Descript"]),c("Address","Descript") ]
add$Count = 1
library(data.table)
dtAdd = data.table(add)
dtAdd
nrow(dtAdd)
dtAdd[,Freq:=sum(Count), by=list(Address, Descript)]
nrow(dtAdd)
dtAdd[,Freq:=sum(Count), by=list(Address, Descript)]
nrow(dtAdd)
dtAdd[,Address]
dtAdd[,c(Address,Descript)]
dtAdd[,c("Address","Descript")]
dtAdd
dtAdd[,Descript]
dfAdd = as.data.frame(dtAdd)
head(dfAdd)
dfAdd = dfAdd[,-c("Count")]
dfAdd[,!names(dfAdd) %in% c("Count")]
unique(dfAdd[,!names(dfAdd) %in% c("Count")])
nrow(unique(dfAdd[,!names(dfAdd) %in% c("Count")]))
nrow(dfAdd)
nrow(unique(dfAdd[,!names(dfAdd) %in% c("Count")]))
theftGroupByAddresses = unique(dfAdd[,!names(dfAdd) %in% c("Count")]))
theftGroupByAddresses = unique(dfAdd[,!names(dfAdd) %in% c("Count")])
summary(theftGroupByAddresses)
theftGroupByCat[with(theftGroupByCat, order(Freq))]
theftGroupByCat = unique(dfAdd[,!names(dfAdd) %in% c("Count")])
theftGroupByCat[with(theftGroupByCat, order(Freq))]
theftGroupByCat[with(theftGroupByCat, order(theftGroupByCat$Freq))]
theftGroupByCat[with(theftGroupByCat, order(theftGroupByCat$Freq)),]
head(theftGroupByCat[with(theftGroupByCat, order(theftGroupByCat$Freq)),])
theftGroupByCat[order(Freq),]
theftGroupByCat[order(theftGroupByCat$Freq),]
nrow(dfAdd)
nrow(theftGroupByCat)
temp = theftGroupByCat[order(theftGroupByCat$Freq),]
nrow(temp)
head(temp)
summary(dfAdd)
temp = theftGroupByCat[order(-theftGroupByCat$Freq),]
nrow(temp)
head(temp)
orderedData = theftGroupByCat[order(theftGroupByCat$Descript, -theftGroupByCat$Freq),]
nrow(temp)
head(temp)
orderedData = theftGroupByCat[order(theftGroupByCat$Descript),]
orderedData = theftGroupByCat[order(theftGroupByCat$Descript, -theftGroupByCat$Freq),]
nrow(orderedData)
head(orderedData)
orderedData = theftGroupByCat[order(-theftGroupByCat$Descript, -theftGroupByCat$Freq),]
orderedData = theftGroupByCat[order(theftGroupByCat$Descript),]
nrow(orderedData)
orderedData
-theftGroupByCat$Freq
orderedData = theftGroupByCat[order(theftGroupByCat$Descript, -theftGroupByCat$Freq),]
nrow(orderedData)
head(orderedData)
orderedData
unique(orderedData[,"Descript"]
unique(orderedData[,"Descript"])
unique(orderedData[,"Descript"])
aggData = aggregate(add, by=list(Address, Descript), FUN=sum)
aggData = aggregate(add, by=list(add$Address, add$Descript), FUN=sum)
aggData = aggregate(add, by=list(add$Address, add$Descript, add$Count), FUN=sum)
aggData = aggregate(theftGroupByCat, by=list(theftGroupByCat$Descript, theftGroupByCat$Freq), FUN=max, na.rm=TRUE)
aggData = aggregate(theftGroupByCat$Freq, by=list(theftGroupByCat$Descript), FUN=max, na.rm=TRUE)
aggData
aggData = aggregate(theftGroupByCat$Freq, by=list(theftGroupByCat$Descript, theftGroupByCat$Address), FUN=max, na.rm=TRUE)
aggData
nrow(aggData)
aggData = aggregate(theftGroupByCat$Freq, by=list(theftGroupByCat$Descript), FUN=max, na.rm=TRUE)
nrow(aggData)
aggData
aggData = aggregate(theftGroupByCat$Freq, by=list(theftGroupByCat$Address, theftGroupByCat$Descript), FUN=max, na.rm=TRUE)
nrow(aggData)
aggData
aggData = aggregate(theftGroupByCat$Freq, by=list(theftGroupByCat$Address, theftGroupByCat$Descript), max, na.rm=TRUE)
nrow(aggData)
aggData = aggregate(theftGroupByCat$Freq, by=list(theftGroupByCat$Descript), FUN=max, na.rm=TRUE)
nrow(aggData)
theftGroupByCat[aggData$Freq == theftGroupByCat$Freq && aggData$Descript == theftGroupByCat$Descript,]
theftGroupByCat[aggData$Freq == theftGroupByCat$Freq & aggData$Descript == theftGroupByCat$Descript,]
aggData$Freq == theftGroupByCat$Freq & aggData$Descript == theftGroupByCat$Descript
aggData$Freq == theftGroupByCat$Freq && aggData$Descript == theftGroupByCat$Descript
head(aggData)
theftGroupByCat[aggData$x == theftGroupByCat$Freq && aggData$Group.1 == theftGroupByCat$Descript,]
aggData$x == theftGroupByCat$Freq && aggData$Group.1 == theftGroupByCat$Descript
